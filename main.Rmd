# Installing Required Packages
```{r}
# install required packages/library
install.packages("matlib")
install.packages("rsample")
install.packages("ggplot2")
install.packages("corrplot")
install.packages("MASS")
install.packages("gridExtra")
install.packages("dplyr")
install.packages("knitr")
```

# Loading Libraries
```{r}
# import required packages/libraries
library(matlib)     # for matrix operations
library(ggplot2)    # for data visualization
library(rsample)    # for data splitting
library(corrplot)   # for correlation visualization
library(MASS)       # for statistical functions
library(gridExtra)  # for arranging plots
library(dplyr)      # for data manipulation
library(knitr)      # for tables
```

# Loading Datasets
```{r}
# load features dataset (independent variable)
features <- as.matrix(read.csv(file="data/features.csv", header=FALSE))
colnames(features) <- c("x1", "x3", "x4", "x5")

# load target dataset (dependent variable)
target <- as.matrix(read.csv(file="data/target.csv", header=FALSE))
colnames(target) <- c("X2")

# load time series dataset
time <- as.matrix((read.csv(file="data/timeseries.csv", header=FALSE)))
colnames(time) <- c("T1")

# display the first few rows of each dataset
cat("Features Dataset: \n")
head(features)

cat("\nTarget Dataset: \n")
head(target)

cat("\nTimeseries Dataset: \n")
head(features)
```

# Summary Statistics
```{r}
# create a combined dataframe
combined_df <- data.frame(
  Temperature = features[,"x1"],
  Ambient_Pressure = features[,"x3"],
  Relative_Humidity = features[,"x4"],
  Exhaust_Vacuum = features[,"x5"],
  Energy_Output = target[,"X2"]
)

# summary statistics
summary_stats <- summary(combined_df)
print(summary_stats)
```

# Task 1: Preliminary Data Analysis
## Time Series Analysis
### Time Series Analysis (Input Signal)
```{r}
# convert features into time series objects
features.ts <- ts(features, start = c(min(time), max(time)), frequency = 1)

# create individual time series plots for each input signal
par(mfrow = c(2, 2), mar = c(4, 4, 2, 1))

# plot for temperature (x1)
plot(features.ts[,"x1"], main = "Time Series - Temperature",
     xlab = "Time", ylab = "Temperature (°C)", col = "darkred")

# plot for ambient pressure (x3)
plot(features.ts[,"x3"], main = "Time Series - Ambient Pressure",
     xlab = "Time", ylab = "Pressure (millibar)", col = "darkblue")

# plot for relative humidity (x4)
plot(features.ts[,"x4"], main = "Time Series - Relative Humidity",
     xlab = "Time", ylab = "Humidity (%)", col = "darkgreen")

# plot for exhaust vacuum (x5)
plot(features.ts[,"x5"], main = "Time Series - Exhaust Vacuum",
     xlab = "Time", ylab = "Vacuum (cm Hg)", col = "darkorange")

# reset layout
par(mfrow = c(1, 1))
```

### Time Series Analysis (Input Signal)
```{r}
# convert target to time series object
target.ts <- ts(target, start = c(min(time), max(time)), frequency = 1)

# plot output signal time series
plot(target.ts, main = "Time Series - Net Hourly Electrical Energy Output",
     xlab = "Time", ylab = "Energy Output (MW)", col = "purple", lwd = 1.5)
```

## Distribution of Each Signal (Output Signal)
```{r}
# function to create enhanced histogram with density plot and normal reference
plot_enhanced_histogram <- function(data, column, title, xlab) {
  # calculate density
  dens <- density(data)
  
  # create histogram
  hist(data, freq = FALSE, main = title, xlab = xlab, col = "lightblue",
    border = "white", ylim = c(0, max(dens$y) * 1.1))
  
  # add density line
  lines(dens, lwd = 2, col = "darkblue")
  
  # add normal distribution reference
  curve(dnorm(x, mean = mean(data), sd = sd(data)), add = TRUE,
    col = "red", lty = 2, lwd = 1.5)
  
  # add legend
  legend("topleft", legend = c("Density", "Normal Reference"),
    col = c("darkblue", "red"), lty = c(1, 2), lwd = c(2, 1.5))
  
  # add mean line
  abline(v = mean(data), col = "darkgreen", lwd = 1.5, lty = 2)
  
  # add text for mean and standard deviation
  usr <- par("usr")  # c(x1, x2, y1, y2)
  text(x = usr[2] - 0.02 * diff(usr[1:2]), y = usr[4] - 0.05 * diff(usr[3:4]),  
    labels = sprintf("Mean: %.2f\nSD:   %.2f", mean(data), sd(data)), adj = c(1, 1))
}

# set up plotting area
par(mfrow = c(3, 2), mar = c(4, 4, 3, 1))

# histogram for temperature (x1)
plot_enhanced_histogram(
  features[,"x1"], 
  "x1", 
  "Distribution of Temperature (x1)", 
  "Ambient temperature (°C)"
)

# histogram for ambient pressure (x3)
plot_enhanced_histogram(
  features[,"x3"], 
  "x3", 
  "Distribution of Ambient Pressure (x3)", 
  "Atmospheric pressure (millibar)"
)

# histogram for relative humidity (x4)
plot_enhanced_histogram(
  features[,"x4"], 
  "x4", 
  "Distribution of Relative Humidity (x4)", 
  "Humidity level (%)"
)

# histogram for exhaust vacuum (x5)
plot_enhanced_histogram(
  features[,"x5"], 
  "x5", 
  "Distribution of Exhaust Vacuum (x5)", 
  "Vacuum (cm Hg)"
)

# histogram for net hourly electrical energy output (X2)
plot_enhanced_histogram(
  target[,"X2"], 
  "X2", 
  "Distribution of Net Hourly Electrical Energy Output (X2)", 
  "Net hourly electrical energy output (MW)"
)

# reset layout to single plot
par(mfrow = c(1, 1))
```

## Correlation Analysis and Scatter Plots
### Correlation Matrix
```{r}
# combine features and target for correlation analysis
combined <- cbind(features, target)

# calculate correlation matrix
correlation <- cor(combined)
print(correlation)

# create enhanced correlation plot
corrplot(correlation, method = "color", type = "upper", 
         addCoef.col = "black", number.cex = 0.7,
         tl.col = "black", tl.srt = 45,
         title = "Correlation Matrix of Power Plant Variables",
         mar = c(0, 0, 1, 0))
```

### Scatter Plots
```{r}
# Define a palette of 4 colors (one per feature)
base_colors <- c("steelblue", "tomato", "forestgreen", "orchid")
# Optionally add a bit of transparency
plot_colors <- sapply(base_colors, function(col) adjustcolor(col, alpha.f = 0.7))

# List of columns and their labels
plots <- list(
  x1 = c("Ambient Temp (°C)",       "Net Energy Output (MW)"),
  x3 = c("Ambient Pressure (mbar)", "Net Energy Output (MW)"),
  x4 = c("Relative Humidity (%)",   "Net Energy Output (MW)"),
  x5 = c("Exhaust Vacuum (cm Hg)",  "Net Energy Output (MW)")
)

# Set up 2 rows × 3 columns
par(mfrow = c(2, 3), mar = c(4, 4, 2, 1))

# Loop over each feature → plot(feature, target) with its own color
i <- 1
for (name in names(plots)) {
  labs <- plots[[name]]
  x    <- features[, name]
  y    <- target[, "X2"]
  
  plot(
    x, y,
    xlab  = labs[1],
    ylab  = labs[2],
    main  = paste(name, "vs X2"),
    pch   = 16,
    cex   = 0.6,
    col   = plot_colors[i]
  )
  i <- i + 1
}

# Leave the last panel empty
plot.new()

# Reset to single plot
par(mfrow = c(1, 1))

```

# Task 2: Regression Modeling
## Model Definitions
```{r}
# model 1: uses relative humidity and squared ambient pressure
model1 <- function(X, theta) {
  return(theta[1] * X$x4 + theta[2] * X$x3^2 + theta[3])
}

# model 2: extends Model 1 by adding exhaust vacuum
model2 <- function(X, theta) {
  return(theta[1] * X$x4 + theta[2] * X$x3^2 + theta[3] * X$x5 + theta[4])
}

# model 3: uses ambient pressure, relative humidity, and cubed exhaust vacuum
model3 <- function(X, theta) {
  return(theta[1] * X$x3 + theta[2] * X$x4 + theta[3] * X$x5^3)
}

# model 4: uses relative humidity, squared ambient pressure, and cubed exhaust vacuum
model4 <- function(X, theta) {
  return(theta[1] * X$x4 + theta[2] * X$x3^2 + theta[3] * X$x5^3 + theta[4])
}

# model 5: uses relative humidity, squared temperature, and squared ambient pressure
model5 <- function(X, theta) {
  return(theta[1] * X$x4 + theta[2] * X$x1^2 + theta[3] * X$x3^2 + theta[4])
}
```


## Task 2.1: Parameter Estimation Using Ridge Regression
```{r}
# convert features matrix into dataframe for easier access in model functions
X <- as.data.frame(features)

# define ridge regression function with regularization parameter lambda
theta_ridge <- function(X, y, lambda = 1e-1) {
  X_bias <- cbind(1, as.matrix(X))
  
  # compute X^T * X
  XtX <- t(X_bias) %*% X_bias
  
  # add regularization term to diagonal 
  XtX_reg <- XtX + lambda * diag(c(0, rep(1, ncol(X))))
  
  # solve using generalized inverse: (X^T*X + λI)^(-1) * X^T * y
  theta <- ginv(XtX_reg) %*% t(X_bias) %*% y
  
  return(theta)
}

# parameters for Model 1
X_model1 <- data.frame(x4 = X$x4, x3 = X$x3^2)
theta_model1 <- theta_ridge(X_model1, target)
cat("Model 1 Parameters:\n")
print(theta_model1)

# parameters for Model 2
X_model2 <- data.frame(x4 = X$x4, x3 = X$x3^2, x5 = X$x5)
theta_model2 <- theta_ridge(X_model2, target)
cat("\nModel 2 Parameters:\n")
print(theta_model2)

# parameters for Model 3
X_model3 <- data.frame(x3 = X$x3, x4 = X$x4, x5 = X$x5^3)
theta_model3 <- theta_ridge(X_model3, target)
cat("\nModel 3 Parameters:\n")
print(theta_model3)

# parameters for Model 4
X_model4 <- data.frame(x4 = X$x4, x3 = X$x3^2, x5 = X$x5^3)
theta_model4 <- theta_ridge(X_model4, target)
cat("\nModel 4 Parameters:\n")
print(theta_model4)

# parameters for Model 5
X_model5 <- data.frame(x4 = X$x4, x1 = X$x1^2, x3 = X$x3^2)
theta_model5 <- theta_ridge(X_model5, target)
cat("\nModel 5 Parameters:\n")
print(theta_model5)
```

## Task 2.2: Model Residual Sum of Squared Error (RSS)
```{r}
# define function to compute Residual Sum of Squares (RSS)
compute_rss <- function(X, y, theta, model) {
  # generate predictions using the model
  y_pred <- model(X, theta)
  
  # calculate RSS as sum of squared differences between actual and predicted values
  rss <- sum((y - y_pred)^2)
  
  return(rss)
}

# calculate RSS for each model
rss_model1 <- compute_rss(X_model1, target, theta_model1, model1)
rss_model2 <- compute_rss(X_model2, target, theta_model2, model2)
rss_model3 <- compute_rss(X_model3, target, theta_model3, model3)
rss_model4 <- compute_rss(X_model4, target, theta_model4, model4)
rss_model5 <- compute_rss(X_model5, target, theta_model5, model5)

cat("Model 1 RSS:\n")
print(rss_model1)

cat("\nModel 2 RSS:\n")
print(rss_model2)

cat("\nModel 3 RSS:\n")
print(rss_model3)

cat("\nModel 4 RSS:\n")
print(rss_model4)

cat("Model 5 RSS:\n")
print(rss_model5)
```

## Task 2.3: Log-likelihood and Variance Calculation
```{r}
# define function to compute log-likelihood and variance
compute_loglikelihood_variance <- function(rss, n) {
  # estimate error variance from RSS
  sigma_squared <- rss / (n - 1)
  
  # compute log-likelihood under Gaussian error assumption
  log_likelihood <- -(n/2) * log(2 * pi) - (n/2) * log(sigma_squared) - 
                   (1/(2 * sigma_squared)) * rss
  
  return(list(log_likelihood = log_likelihood, variance = sigma_squared))
}

# calculate log-likelihood and variance for each model
n_samples <- length(target)  # number of observations

# model 1
compute_model1 <- compute_loglikelihood_variance(rss_model1, n_samples)
model1_log_likelihood <- compute_model1$log_likelihood
model1_variance <- compute_model1$variance

# model 2
compute_model2 <- compute_loglikelihood_variance(rss_model2, n_samples)
model2_log_likelihood <- compute_model2$log_likelihood
model2_variance <- compute_model2$variance

# model 3
compute_model3 <- compute_loglikelihood_variance(rss_model3, n_samples)
model3_log_likelihood <- compute_model3$log_likelihood
model3_variance <- compute_model3$variance

# model 4
compute_model4 <- compute_loglikelihood_variance(rss_model4, n_samples)
model4_log_likelihood <- compute_model4$log_likelihood
model4_variance <- compute_model4$variance

# model 5
compute_model5 <- compute_loglikelihood_variance(rss_model5, n_samples)
model5_log_likelihood <- compute_model5$log_likelihood
model5_variance <- compute_model5$variance


cat("Model 1:")
cat("\nLog-likelihood:", model1_log_likelihood)
cat("\nVariance:", model1_variance)

cat("\n\nModel 2:")
cat("\nLog-likelihood:", model2_log_likelihood)
cat("\nVariance:", model2_variance)

cat("\n\nModel 3:")
cat("\nLog-likelihood:", model3_log_likelihood)
cat("\nVariance:", model3_variance)

cat("\n\nModel 4:")
cat("\nLog-likelihood:", model4_log_likelihood)
cat("\nVariance:", model4_variance)

cat("\n\nModel 5:")
cat("\nLog-likelihood:", model5_log_likelihood)
cat("\nVariance:", model5_variance)
```

## Task 2.4: Compute AIC and BIC
```{r}
# define functions to compute AIC and BIC
compute_aic <- function(log_likelihood, k) {
  aic <- 2 * k - 2 * log_likelihood
  return(aic)
}

compute_bic <- function(log_likelihood, k, n) {
  bic <- k * log(n) - 2 * log_likelihood
  return(bic)
}

model1_k <- length(theta_model1)
model2_k <- length(theta_model2)
model3_k <- length(theta_model3)
model4_k <- length(theta_model4)
model5_k <- length(theta_model5)

# Calculate AIC and BIC for each model
model1_aic <- compute_aic(model1_log_likelihood, model1_k)
model1_bic <- compute_bic(model1_log_likelihood, model1_k, n_samples)

model2_aic <- compute_aic(model2_log_likelihood, model2_k)
model2_bic <- compute_bic(model2_log_likelihood, model2_k, n_samples)

model3_aic <- compute_aic(model3_log_likelihood, model3_k)
model3_bic <- compute_bic(model3_log_likelihood, model3_k, n_samples)

model4_aic <- compute_aic(model4_log_likelihood, model4_k)
model4_bic <- compute_bic(model4_log_likelihood, model4_k, n_samples)

model5_aic <- compute_aic(model5_log_likelihood, model5_k)
model5_bic <- compute_bic(model5_log_likelihood, model5_k, n_samples)

cat("Model 1:")
cat("\nAIC:", model1_aic)
cat("\nBIC:", model1_bic)

cat("\n\nModel 2:")
cat("\nAIC:", model2_aic)
cat("\nBIC:", model2_bic)

cat("\n\nModel 3:")
cat("\nAIC:", model3_aic)
cat("\nBIC:", model3_bic)

cat("\n\nModel 4:")
cat("\nAIC:", model4_aic)
cat("\nBIC:", model4_bic)

cat("\n\nModel 5:")
cat("\nAIC:", model5_aic)
cat("\nBIC:", model5_bic)
```


## Task 2.5: Distribution of Model Prediction Errors
```{r}
# define function to compute model prediction errors (residuals)
compute_model_prediction_error <- function(X, y, theta, model) {
  # generate predictions using the model
  y_pred <- model(X, theta)
  
  # calculate prediction errors/residuals
  prediction_error <- y - y_pred
  
  return(prediction_error)
}

# calculate prediction errors for each model
prediction_error_model1 <- compute_model_prediction_error(X_model1, target, theta_model1, model1)
prediction_error_model2 <- compute_model_prediction_error(X_model2, target, theta_model2, model2)
prediction_error_model3 <- compute_model_prediction_error(X_model3, target, theta_model3, model3)
prediction_error_model4 <- compute_model_prediction_error(X_model4, target, theta_model4, model4)
prediction_error_model5 <- compute_model_prediction_error(X_model5, target, theta_model5, model5)

# create enhanced QQ plots to check for normality of residuals
par(mfrow = c(2, 3), mar = c(4, 4, 3, 1))

# function to create enhanced QQ plot
create_enhanced_qq <- function(residuals, model_name) {
  # generate QQ plot
  qqnorm(residuals, main = paste("Q-Q Plot of Residuals for", model_name),
         col = "blue", pch = 19, cex = 0.5)
  qqline(residuals, col = "red", lwd = 2)
  
}

# create QQ plots for all models
create_enhanced_qq(prediction_error_model1, "Model 1")
create_enhanced_qq(prediction_error_model2, "Model 2")
create_enhanced_qq(prediction_error_model3, "Model 3")
create_enhanced_qq(prediction_error_model4, "Model 4")
create_enhanced_qq(prediction_error_model5, "Model 5")

# reset plot layout
par(mfrow = c(1, 1))
```

```{r}
# compile all model evaluation metrics into a comprehensive table
model_comparison <- data.frame(
  Model = c("Model 1", "Model 2", "Model 3", "Model 4", "Model 5"),
  Parameters = c(model1_k, model2_k, model3_k, model4_k, model5_k),
  RSS = c(rss_model1, rss_model2, rss_model3, rss_model4, rss_model5),
  LogLikelihood = c(model1_log_likelihood, model2_log_likelihood, 
                   model3_log_likelihood, model4_log_likelihood, 
                   model5_log_likelihood),
  AIC = c(model1_aic, model2_aic, model3_aic, model4_aic, model5_aic),
  BIC = c(model1_bic, model2_bic, model3_bic, model4_bic, model5_bic),
  Variance = c(model1_variance, model2_variance, model3_variance, 
              model4_variance, model5_variance)
)

# display the comprehensive table
kable(model_comparison, 
      caption = "Comprehensive Comparison of All Models", 
      digits = c(0, 0, 2, 2, 2, 2, 4))

# rank models based on different criteria
rank_rss <- rank(model_comparison$RSS)
rank_aic <- rank(model_comparison$AIC)
rank_bic <- rank(model_comparison$BIC)
rank_loglik <- rank(-model_comparison$LogLikelihood)  # Negative because higher is better

ranking_table <- data.frame(
  Model = model_comparison$Model,
  RSS_Rank = rank_rss,
  AIC_Rank = rank_aic,
  BIC_Rank = rank_bic,
  LogLikelihood_Rank = rank_loglik,
  Overall_Rank = rank_rss + rank_aic + rank_bic + rank_loglik
)

# sort by overall rank (lower is better)
ranking_table <- ranking_table[order(ranking_table$Overall_Rank),]

# display the ranking table
kable(ranking_table, 
      caption = "Model Ranking Based on Different Criteria (Lower is Better)")

# determine the best model based on our criteria
best_model_index <- which.min(model_comparison$AIC)
best_model_name <- model_comparison$Model[best_model_index]

cat(paste("Based on AIC, the best model is:", best_model_name, "\n"))
cat(paste("Based on BIC, the best model is:", model_comparison$Model[which.min(model_comparison$BIC)], "\n"))
cat(paste("Based on Log-Likelihood, the best model is:", model_comparison$Model[which.max(model_comparison$LogLikelihood)], "\n"))
cat(paste("Based on RSS, the best model is:", model_comparison$Model[which.min(model_comparison$RSS)], "\n"))
```

## Train-Test Split
```{r}
set.seed(123)

# create indices for 70% train, 30% test split
sample_size <- nrow(features)
train_indices <- sample(sample_size, size = round(0.7 * sample_size))
test_indices <- setdiff(1:sample_size, train_indices)

# create training and testing datasets
train_features <- features[train_indices, ]
train_target <- target[train_indices, ]
test_features <- features[test_indices, ]
test_target <- target[test_indices, ]

train_X <- data.frame(x4 = train_features[,"x4"], 
                     x1_squared = train_features[,"x1"]^2, 
                     x3_squared = train_features[,"x3"]^2)
                     
test_X <- data.frame(x4 = test_features[,"x4"], 
                    x1_squared = test_features[,"x1"]^2, 
                    x3_squared = test_features[,"x3"]^2)

# estimate parameters using training data
train_theta <- theta_ridge(train_X, train_target)
cat("Model 5 parameters estimated on training data:\n")
print(train_theta)

# calculate predictions on test data
test_predictions <- model5(test_X, train_theta)

# calculate test error metrics
test_rss <- sum((test_target - test_predictions)^2)
test_rmse <- sqrt(mean((test_target - test_predictions)^2))
test_mae <- mean(abs(test_target - test_predictions))
test_r_squared <- 1 - sum((test_target - test_predictions)^2) / sum((test_target - mean(test_target))^2)

# display test metrics
test_metrics <- data.frame(
  Metric = c("RSS", "RMSE", "MAE", "R-squared"),
  Value = c(test_rss, test_rmse, test_mae, test_r_squared)
)

kable(test_metrics, caption = "Model Performance on Test Data")
```

### Calculate Confidence Intervals and Visualization
```{r}
# function to compute confidence intervals for predictions
compute_confidence_intervals <- function(predictions, variance, confidence_level = 0.95) {
  # number of observations
  n_obs <- length(predictions)
  
  # calculate margin of error for the confidence interval
  alpha <- 1 - confidence_level
  t_critical <- qt(1 - alpha/2, df = n_obs - 4)  # 4 parameters in Model 5
  margin_error <- t_critical * sqrt(variance)
  
  # return lower and upper bounds
  return(list(
    lower = predictions - margin_error,
    upper = predictions + margin_error
  ))
}

# compute the variance of model prediction errors from training data
model5_prediction_errors <- train_target - model5(train_X, train_theta)
model5_prediction_variance <- var(model5_prediction_errors)

# compute 95% confidence intervals
ci <- compute_confidence_intervals(test_predictions, model5_prediction_variance, 0.95)

# create dataframe for plotting
plot_data <- data.frame(
  Observation = 1:length(test_predictions),
  Actual = test_target,
  Predicted = test_predictions,
  Lower_CI = ci$lower,
  Upper_CI = ci$upper
)

# create visualization of predictions with confidence intervals
ggplot(plot_data, aes(x = Observation)) +
  # plot actual observations
  geom_point(aes(y = Actual), color = "blue", alpha = 0.5, size = 1.5) +
  # plot predicted values
  geom_line(aes(y = Predicted), color = "red", size = 1) +
  # add confidence interval ribbon
  geom_ribbon(aes(ymin = Lower_CI, ymax = Upper_CI), alpha = 0.2, fill = "gray") +
  # customize plot appearance
  theme_minimal() +
  labs(
    title = "Test Data Predictions with 95% Confidence Intervals - Model 5",
    x = "Observation Index",
    y = "Net Hourly Electrical Energy Output (MW)"
  ) +
  theme(
    plot.title = element_text(face = "bold"),
    axis.title = element_text(face = "bold")
  )
```

